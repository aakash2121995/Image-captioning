{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c76bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42785684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b7403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embedding_size, vocab_size, hidden_size, start_token, end_token, pad_token):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "        self.pad_token = pad_token\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_size)\n",
    "        self.lstm = nn.LSTMCell(embedding_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size,vocab_size)\n",
    "        self.init_h = nn.Linear(512, hidden_size)  # linear layer to find initial hidden state of LSTMCell\n",
    "        self.init_c = nn.Linear(512, hidden_size)  # linear layer to find initial cell state of LSTMCell\n",
    "        self.vocab_size = vocab_size\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    def forward(self, features, captions, caption_lengths):\n",
    "        batch_size = features.shape[0]\n",
    "        sorted_caption_lengths, sort_ind = caption_lengths.sort(descending=True)\n",
    "        features = features[sort_ind]\n",
    "        captions = captions[sort_ind]\n",
    "        caption_embeddings = self.embedding(captions)\n",
    "        decode_lengths = sorted_caption_lengths - 1\n",
    "        output = torch.zeros((batch_size,int(decode_lengths.max()),self.vocab_size))\n",
    "        hx = self.init_h(features) \n",
    "        cx = self.init_c(features)\n",
    "        for t in range(int(decode_lengths.max())):\n",
    "            batch_size_t = int((decode_lengths > t).sum())\n",
    "            hx, cx = self.lstm(caption_embeddings[:batch_size_t,t,:], (hx[:batch_size_t], cx[:batch_size_t]))\n",
    "            raw_scores = self.fc(hx)\n",
    "            output[:batch_size_t,t,:] = raw_scores       \n",
    "        return output, sort_ind\n",
    "    \n",
    "    def predict(self, features):\n",
    "        batch_size = features.shape[0]\n",
    "        hx = self.init_h(features) \n",
    "        cx = self.init_c(features)\n",
    "        eok_pred = torch.tensor([False]*batch_size, device=self.device)\n",
    "        current_pred = torch.tensor(batch_size*[self.start_token], device=self.device)\n",
    "        output = []\n",
    "        predictions = []\n",
    "        i = 0\n",
    "        while eok_pred.sum() < batch_size and i < 100:\n",
    "            unfinished_pred = current_pred != self.end_token\n",
    "            hx_, cx_ = self.lstm(self.embedding(current_pred[unfinished_pred]), (hx[unfinished_pred], cx[unfinished_pred]))\n",
    "            raw_scores = self.fc(hx_)\n",
    "            hx[unfinished_pred] = hx_\n",
    "            cx[unfinished_pred] = cx_\n",
    "            output.append(raw_scores)\n",
    "            prediction = raw_scores.argmax(1)\n",
    "            predictions.append(prediction)\n",
    "            current_pred[unfinished_pred] = prediction\n",
    "            eok_pred[current_pred == self.end_token] = True\n",
    "            i = i + 1\n",
    "        return nn.utils.rnn.pad_sequence(output), nn.utils.rnn.pad_sequence(predictions, batch_first=False, padding_value=self.pad_token)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9259202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderImprovedTraining(nn.Module):\n",
    "    def __init__(self, embedding_size, vocab_size, hidden_size, start_token, end_token, pad_token):\n",
    "        super(DecoderImprovedTraining,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "        self.pad_token = pad_token\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size,hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size,vocab_size)\n",
    "        self.init_h = nn.Linear(512, hidden_size)  # linear layer to find initial hidden state of LSTMCell\n",
    "        self.init_c = nn.Linear(512, hidden_size)  # linear layer to find initial cell state of LSTMCell\n",
    "        self.vocab_size = vocab_size\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    def forward(self, features, captions, caption_length):\n",
    "        batch_size = features.shape[0]\n",
    "        caption_embeddings = self.embedding(captions)\n",
    "        caption_embeddings_packed = nn.utils.rnn.pack_padded_sequence(caption_embeddings,caption_length.cpu()-1,True)\n",
    "        hx = self.init_h(features).unsqueeze(0)\n",
    "        cx = self.init_c(features).unsqueeze(0)\n",
    "        hx, cx = self.lstm(caption_embeddings_packed,(hx, cx))\n",
    "        hx_unpacked, lens_unpacked = nn.utils.rnn.pad_packed_sequence(hx,padding_value=0, batch_first=True)\n",
    "        raw_scores = self.fc(hx_unpacked)\n",
    "        return raw_scores\n",
    "    \n",
    "    def prepare_for_prediction(self, beam_width):\n",
    "        self.lstm_cell = nn.LSTMCell(self.embedding_size,self.hidden_size,device=self.device)\n",
    "        self.lstm_cell.load_state_dict({ key[:-3]:state for key,state in self.lstm.state_dict().items()})\n",
    "        self.beam_width = beam_width\n",
    "    \n",
    "    def predict_first_tokens(self, features):\n",
    "        batch_size = features.shape[0]\n",
    "        h0 = self.init_h(features) \n",
    "        c0 = self.init_c(features)\n",
    "        start_tokens = torch.tensor(batch_size*[self.start_token], device=self.device)\n",
    "        h1, c1 = self.lstm_cell(self.embedding(start_tokens), (h0, c0))\n",
    "        raw_scores = self.fc(h1)\n",
    "        raw_scores = nn.functional.log_softmax(raw_scores,1)\n",
    "        score, tokens = raw_scores.topk(self.beam_width,dim=1) #should be shaped batchsize x beam_width\n",
    "        return score, tokens, h1, c1\n",
    "    \n",
    "    def predict_next_token(self,score,h_i,c_i,tokens):\n",
    "        h, c = self.lstm_cell(self.embedding(tokens), (h_i, c_i))\n",
    "        raw_scores = nn.functional.log_softmax(self.fc(h),1)\n",
    "        total_score = raw_scores + score.unsqueeze(dim=-1)\n",
    "        total_score = total_score.flatten()\n",
    "        new_score, new_tokens = total_score.topk(self.beam_width)\n",
    "        return new_score, new_tokens, h, c\n",
    "    \n",
    "    def predict(self, features):\n",
    "        batch_size = features.shape[0]\n",
    "        hx = self.init_h(features) \n",
    "        cx = self.init_c(features)\n",
    "        eok_pred = torch.tensor([False]*batch_size, device=self.device)\n",
    "        current_pred = torch.tensor(batch_size*[self.start_token], device=self.device)\n",
    "        output = []\n",
    "        predictions = []\n",
    "        i = 0\n",
    "        while eok_pred.sum() < batch_size and i < 100:\n",
    "            unfinished_pred = current_pred != self.end_token\n",
    "            hx_, cx_ = self.lstm_cell(self.embedding(current_pred[unfinished_pred]), (hx[unfinished_pred], cx[unfinished_pred]))\n",
    "            raw_scores = self.fc(hx_)\n",
    "            hx[unfinished_pred] = hx_\n",
    "            cx[unfinished_pred] = cx_\n",
    "            output.append(raw_scores)\n",
    "            prediction = raw_scores.argmax(1)\n",
    "            predictions.append(prediction)\n",
    "            current_pred[unfinished_pred] = prediction\n",
    "            eok_pred[current_pred == self.end_token] = True\n",
    "            i = i + 1\n",
    "        return nn.utils.rnn.pad_sequence(output), nn.utils.rnn.pad_sequence(predictions, batch_first=False, padding_value=self.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d01e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderPretrainedEmbeddings(nn.Module):\n",
    "    def __init__(self, embedding_matrix, vocab_size, hidden_size, start_token, end_token, pad_token):\n",
    "        super(DecoderPretrainedEmbeddings,self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.hidden_size = hidden_size\n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "        self.pad_token = pad_token\n",
    "        self.embedding_size = embedding_matrix.shape[1]\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix.to(self.device),freeze=False)\n",
    "        self.lstm = nn.LSTM(self.embedding_size,hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size,vocab_size)\n",
    "        self.init_h = nn.Linear(512, hidden_size)  # linear layer to find initial hidden state of LSTMCell\n",
    "        self.init_c = nn.Linear(512, hidden_size)  # linear layer to find initial cell state of LSTMCell\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "    def forward(self, features, captions, caption_length):\n",
    "        batch_size = features.shape[0]\n",
    "        caption_embeddings = self.embedding(captions)\n",
    "        caption_embeddings_packed = nn.utils.rnn.pack_padded_sequence(caption_embeddings,caption_length.cpu()-1,True)\n",
    "        hx = self.init_h(features).unsqueeze(0)\n",
    "        cx = self.init_c(features).unsqueeze(0)\n",
    "        hx, cx = self.lstm(caption_embeddings_packed,(hx, cx))\n",
    "        hx_unpacked, lens_unpacked = nn.utils.rnn.pad_packed_sequence(hx,padding_value=0, batch_first=True)\n",
    "        raw_scores = self.fc(hx_unpacked)\n",
    "        return raw_scores\n",
    "    \n",
    "    def prepare_for_prediction(self, beam_width):\n",
    "        self.lstm_cell = nn.LSTMCell(self.embedding_size,self.hidden_size,device=self.device)\n",
    "        self.lstm_cell.load_state_dict({ key[:-3]:state for key,state in self.lstm.state_dict().items()})\n",
    "        self.beam_width = beam_width\n",
    "    \n",
    "    def predict_first_tokens(self, features):\n",
    "        batch_size = features.shape[0]\n",
    "        h0 = self.init_h(features) \n",
    "        c0 = self.init_c(features)\n",
    "        start_tokens = torch.tensor(batch_size*[self.start_token], device=self.device)\n",
    "        h1, c1 = self.lstm_cell(self.embedding(start_tokens), (h0, c0))\n",
    "        raw_scores = self.fc(h1)\n",
    "        raw_scores = nn.functional.log_softmax(raw_scores,1)\n",
    "        score, tokens = raw_scores.topk(self.beam_width,dim=1) #should be shaped batchsize x beam_width\n",
    "        return score, tokens, h1, c1\n",
    "    \n",
    "    def predict_next_token(self,score,h_i,c_i,tokens):\n",
    "        h, c = self.lstm_cell(self.embedding(tokens), (h_i, c_i))\n",
    "        raw_scores = nn.functional.log_softmax(self.fc(h),1)\n",
    "        total_score = raw_scores + score.unsqueeze(dim=-1)\n",
    "        total_score = total_score.flatten()\n",
    "        new_score, new_tokens = total_score.topk(self.beam_width)\n",
    "        return new_score, new_tokens, h, c\n",
    "    \n",
    "    def predict(self, features):\n",
    "        batch_size = features.shape[0]\n",
    "        hx = self.init_h(features) \n",
    "        cx = self.init_c(features)\n",
    "        eok_pred = torch.tensor([False]*batch_size, device=self.device)\n",
    "        current_pred = torch.tensor(batch_size*[self.start_token], device=self.device)\n",
    "        output = []\n",
    "        predictions = []\n",
    "        i = 0\n",
    "        while eok_pred.sum() < batch_size and i < 100:\n",
    "            unfinished_pred = current_pred != self.end_token\n",
    "            hx_, cx_ = self.lstm_cell(self.embedding(current_pred[unfinished_pred]), (hx[unfinished_pred], cx[unfinished_pred]))\n",
    "            raw_scores = self.fc(hx_)\n",
    "            hx[unfinished_pred] = hx_\n",
    "            cx[unfinished_pred] = cx_\n",
    "            output.append(raw_scores)\n",
    "            prediction = raw_scores.argmax(1)\n",
    "            predictions.append(prediction)\n",
    "            current_pred[unfinished_pred] = prediction\n",
    "            eok_pred[current_pred == self.end_token] = True\n",
    "            i = i + 1\n",
    "        return nn.utils.rnn.pad_sequence(output), nn.utils.rnn.pad_sequence(predictions, batch_first=False, padding_value=self.pad_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8602b690",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDecoderPretrainedWithImageFeatureForPrediction\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, feature_size, embedding_matrix, hidden_size, vocab_size, start_token, end_token, pad_token):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(DecoderPretrainedWithImageFeatureForPrediction,\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class DecoderPretrainedWithImageFeatureForPrediction(nn.Module):\n",
    "    def __init__(self, feature_size, embedding_matrix, hidden_size, vocab_size, start_token, end_token, pad_token):\n",
    "        super(DecoderPretrainedWithImageFeatureForPrediction,self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.hidden_size = hidden_size\n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "        self.pad_token = pad_token\n",
    "        self.embedding_size = embedding_matrix.shape[1]\n",
    "        self.features_to_embedding = nn.Linear(feature_size, self.embedding_size)\n",
    "        self.features_to_hidden = nn.Linear(feature_size, self.hidden_size)\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix.to(self.device),freeze=False)\n",
    "        self.lstm = nn.LSTM(self.embedding_size,hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size,vocab_size)\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "    def forward(self, features, captions, caption_length):\n",
    "        batch_size = features.shape[0]\n",
    "        feature_embeddings = nn.functional.relu(self.features_to_embedding(features).unsqueeze(1))\n",
    "        caption_embeddings = self.embedding(captions)\n",
    "        all_embeddings = torch.cat([feature_embeddings, caption_embeddings], dim=1)\n",
    "        hx = torch.zeros((1,batch_size, self.hidden_size)).to(self.device)\n",
    "        cx = torch.zeros((1,batch_size, self.hidden_size)).to(self.device)\n",
    "        caption_embeddings_packed = nn.utils.rnn.pack_padded_sequence(all_embeddings,caption_length.cpu(),True)\n",
    "        hx, cx = self.lstm(caption_embeddings_packed,(hx, cx))\n",
    "        hx_unpacked, lens_unpacked = nn.utils.rnn.pad_packed_sequence(hx,padding_value=0, batch_first=True)\n",
    "        features_hidden = nn.functional.relu(self.features_to_hidden(features).unsqueeze(1))\n",
    "        fc_inp = hx_unpacked + features_hidden \n",
    "        raw_scores = self.fc(fc_inp)\n",
    "        return raw_scores\n",
    "    \n",
    "    def prepare_for_prediction(self, beam_width):\n",
    "        self.lstm_cell = nn.LSTMCell(self.embedding_size,self.hidden_size,device=self.device)\n",
    "        self.lstm_cell.load_state_dict({ key[:-3]:state for key,state in self.lstm.state_dict().items()})\n",
    "        self.beam_width = beam_width\n",
    "    \n",
    "    def predict_first_tokens(self, features):\n",
    "        batch_size = features.shape[0]\n",
    "        h0 = torch.zeros((batch_size, self.hidden_size)).to(self.device)\n",
    "        c0 = torch.zeros((batch_size, self.hidden_size)).to(self.device)\n",
    "        feature_embeddings = nn.functional.relu(self.features_to_embedding(features))\n",
    "        features_hidden = nn.functional.relu(self.features_to_hidden(features))\n",
    "        h1, c1 = self.lstm_cell(feature_embeddings, (h0, c0))\n",
    "        raw_scores = self.fc(h1 + features_hidden)\n",
    "        raw_scores = nn.functional.log_softmax(raw_scores,1)\n",
    "        score, tokens = raw_scores.topk(self.beam_width,dim=1) #should be shaped batchsize x beam_width\n",
    "        return score, tokens, h1, c1\n",
    "    \n",
    "    def predict_next_token(self,features, score,h_i,c_i,tokens):\n",
    "        features_hidden = nn.functional.relu(self.features_to_hidden(features))\n",
    "        h, c = self.lstm_cell(self.embedding(tokens), (h_i, c_i))\n",
    "        raw_scores = nn.functional.log_softmax(self.fc(h + features_hidden),1)\n",
    "        total_score = raw_scores + score.unsqueeze(dim=-1)\n",
    "        total_score = total_score.flatten()\n",
    "        new_score, new_tokens = total_score.topk(self.beam_width)\n",
    "        return new_score, new_tokens, h, c\n",
    "    \n",
    "    def predict(self, features):\n",
    "        batch_size = features.shape[0]\n",
    "        hx = torch.zeros((batch_size, self.hidden_size)).to(self.device)\n",
    "        cx = torch.zeros((batch_size, self.hidden_size)).to(self.device)\n",
    "        feature_embeddings = nn.functional.relu(self.features_to_embedding(features))\n",
    "        eok_pred = torch.tensor([False]*batch_size, device=self.device)\n",
    "        current_pred = torch.tensor(batch_size*[self.start_token], device=self.device)\n",
    "        output = []\n",
    "        predictions = []\n",
    "        i = 0\n",
    "        features_hidden = nn.functional.relu(self.features_to_hidden(features))\n",
    "        while eok_pred.sum() < batch_size and i < 50:\n",
    "            \n",
    "            unfinished_pred = current_pred != self.end_token\n",
    "            if i == 0:\n",
    "                embeddings = feature_embeddings\n",
    "            else:\n",
    "                embeddings = self.embedding(current_pred[unfinished_pred])\n",
    "            hx_, cx_ = self.lstm_cell(embeddings, (hx[unfinished_pred], cx[unfinished_pred]))\n",
    "            raw_scores = self.fc(hx_ + features_hidden[unfinished_pred])\n",
    "            hx[unfinished_pred] = hx_\n",
    "            cx[unfinished_pred] = cx_\n",
    "            output.append(raw_scores)\n",
    "            prediction_array = torch.ones(batch_size).type(torch.LongTensor).to(self.device)*self.pad_token\n",
    "            prediction = raw_scores.argmax(1)\n",
    "            prediction_array[unfinished_pred] = prediction\n",
    "            predictions.append(prediction_array)\n",
    "            current_pred[unfinished_pred] = prediction\n",
    "            eok_pred[current_pred == self.end_token] = True\n",
    "            i = i + 1\n",
    "        \n",
    "        predictions = torch.stack(predictions).T\n",
    "        pred_lengths = predictions.shape[1] - (predictions == self.pad_token).sum(1)\n",
    "                \n",
    "        return nn.utils.rnn.pad_sequence(output,), predictions, pred_lengths"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
